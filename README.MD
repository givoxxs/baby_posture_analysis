# Baby Posture Analysis

<div align="center">

![Baby Posture Analysis](https://img.shields.io/badge/Project-Baby_Posture_Analysis-blue)
![Python](https://img.shields.io/badge/Python-3.8+-green)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-blue)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Latest-orange)
![OpenCV](https://img.shields.io/badge/OpenCV-Latest-red)
![License](https://img.shields.io/badge/License-MIT-yellow)

</div>

## üìã Overview

A sophisticated system for analyzing baby posture in images to detect potential safety risks during sleep. This project uses computer vision and machine learning to identify potentially dangerous sleeping positions and provide recommendations for safer baby sleep practices.

## ‚ú® Features

- **Advanced Image Analysis**: Process and enhance images for optimal pose detection
- **MediaPipe Integration**: Skeletal keypoint detection with 3D coordinates
- **ML-Powered Risk Assessment**: Evaluate baby sleeping positions for safety concerns
- **Detailed Analysis Reports**: Get comprehensive insights on posture risks
- **API-First Design**: RESTful endpoints for easy integration with other systems
- **Interactive Web Interface**: Simple visual testing of the analysis system

## üèóÔ∏è Architecture

The system follows a modular pipeline architecture:

### 1. Image Preprocessing Module

- Image normalization and enhancement
- Noise reduction and filtering
- Dimension standardization
- Quality optimization for pose detection

### 2. Keypoint Extraction Module

- MediaPipe Pose for skeletal keypoint detection
- 33 standard body keypoints with 3D coordinates (x, y, z)
- Confidence scores for reliable pose estimation
- Visibility metrics for each detected keypoint

### 3. Posture Feature Construction Module

- Head-torso angle detection for sleeping position
- Limb angle calculations for unnatural positions
- Blanket coverage detection
- Face-down position detection (higher risk factor)

### 4. Risk Analysis Module

- Comprehensive assessment of sleeping position safety
- Risk scoring system (1-10 scale)
- Detailed reasoning for risk assessment
- Specific recommendations based on identified risks

## üõ†Ô∏è Technologies

- **Python 3.8+**: Core programming language
- **FastAPI**: High-performance web framework
- **MediaPipe**: Google's ML solution for pose estimation
- **OpenCV**: Computer vision for image processing
- **NumPy/Pandas**: Data manipulation and analysis
- **Scikit-learn**: Machine learning models
- **PIL/Pillow**: Image handling and processing

## üöÄ Setup & Installation

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- Git

### Installation Steps

1. **Clone the repository**:
   ```bash
   git clone https://github.com/givoxxs/baby_posture_analysis.git
   cd baby_posture_analysis
   ```

2. **Set up a virtual environment (recommended)**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Environment configuration**:
   Copy the `.env.example` file to create your own `.env` file:
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file to configure your settings:
   ```
   # Firebase Storage
   CLOUDINARY_CLOUD_NAME=your_cloud_name   
   CLOUDINARY_API_KEY=your_api_key
   CLOUDINARY_API_SECRET=your_api_secret

   # Ngrok Configuration (optional, for public URL access)
   NGROK_AUTHTOKEN=your_ngrok_authtoken

   # FastAPI Settings
   API_HOST=0.0.0.0
   API_PORT=8080
   # Other settings...
   ```

## üñ•Ô∏è Usage

### Starting the Server

You can start the server using one of the following methods:

1. **Using the Python module directly**:
   ```bash
   python -m app.main
   ```

2. **Using Uvicorn with options from your `.env` file**:
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8080
   ```

3. **Or simply with default configuration**:
   ```bash
   uvicorn app.main:app --reload
   ```

2. **Access the API documentation**:
   Open your web browser and navigate to:
   ```
   http://localhost:8080/docs
   ```
   This provides interactive Swagger UI documentation for testing all API endpoints.

3. **Test with the web interface**:
   Open your browser and go to:
   ```
   http://localhost:8080
   ```
   The simple web interface allows you to upload images and visualize the analysis results.

## üì° API Endpoints

### Image Processing

- **POST** `/api/images/process`
  - Process an image with quality enhancements
  - **Parameters**: 
    - `file`: Image file upload (required)
    - `high_resolution`: Boolean to maintain higher resolution (optional)
    - `apply_filter`: Boolean to apply image enhancement filters (optional)
  - **Returns**: Processed image with quality improvements

### Pose Detection

- **POST** `/api/pose/detect`
  - Detect pose keypoints from an image
  - **Parameters**:
    - `file`: Image file upload (required)
    - `high_resolution`: Boolean to maintain higher resolution (optional)
    - `include_annotated_image`: Boolean to include visualized keypoints (optional)
    - `include_analysis`: Boolean to include basic analysis (optional)
  - **Returns**: Detected keypoints and optional analysis

### Posture Analysis

- **POST** `/api/pose/analyze`
  - Analyze baby posture and risk level
  - **Parameters**:
    - `file`: Image file upload (required)
    - `high_resolution`: Boolean to maintain higher resolution (optional)
  - **Returns**: Comprehensive posture analysis and risk assessment

### Complete Pipeline

- **POST** `/api/pipeline/analyze`
  - Process image, detect pose, and analyze risk in one request
  - **Parameters**:
    - `file`: Image file upload (required)
    - `high_resolution`: Boolean to maintain higher resolution (optional)
  - **Returns**: Complete analysis with:
    - Position detection
    - Face-down detection
    - Coverage assessment
    - Risk level and score
    - Confidence rating
    - Analysis reasoning
    - Safety recommendations
    - Annotated image

### Video Analysis

- **POST** `/api/video/analyze`
  - Analyze baby posture from video footage
  - **Parameters**:
    - `file`: Video file upload (required)
    - `sample_rate`: Frames per second to analyze (optional)
  - **Returns**: Time-series analysis of posture throughout the video

## üî¨ Machine Learning Models

This system uses trained machine learning models to analyze posture features:

- **Random Forest Classification**: Used for posture classification
- **Feature Scaling**: Input normalization for consistent analysis
- **Pre-trained Models**: Located in the `app/models` directory
- **Model Training**: Notebooks for model training in `ML_train` directory

## üß™ Testing

The project includes notebooks for testing and validation:
- `ML_train/5_test_each_image.ipynb`: Individual image testing
- `ML_train/4_test.ipynb`: Model validation tests

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## üìß Contact

Project Developer - [Phan VƒÉn To√†n](mailto:phanvantoan.contact@gmail.com)

Project Link: [https://github.com/givoxxs/baby_posture_analysis](https://github.com/givoxxs/baby_posture_analysis)